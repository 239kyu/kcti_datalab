{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_P0vEm_sXWJScN29cjchJOAuQlWEQkuq",
      "authorship_tag": "ABX9TyOlMir0Sic3SZxFzDlac3JE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/239kyu/kcti_datalab/blob/main/langchain_pdf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#모듈 설치"
      ],
      "metadata": {
        "id": "7UuWQgPaTKx8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbUdBHlqxt_t",
        "outputId": "2a2df9dc-d786-4fb2-ff11-28acd4278f06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for chroma (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip install -q openai langchain pypdf chroma"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4kYrZUv1opc",
        "outputId": "1f5005db-0702-4875-ab8b-62344ea7ee1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.1.1)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.6.3)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.2)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.10.0)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.23.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.23.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.23.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.2)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.2)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.1.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.62.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.2.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson>=3.9.12 (from chromadb)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (23.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata<7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.23.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl (28 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl (36 kB)\n",
            "Collecting opentelemetry-util-http==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.44b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.6)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (3.7.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=1b954cef6b07be62568e2c1a26381b464cd79f95ebada1c30014c71c7e4c7f65\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, python-dotenv, pulsar-client, overrides, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, importlib-metadata, humanfriendly, httptools, h11, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 7.0.1\n",
            "    Uninstalling importlib-metadata-7.0.1:\n",
            "      Successfully uninstalled importlib-metadata-7.0.1\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.2 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 deprecated-1.2.14 fastapi-0.110.0 h11-0.14.0 httptools-0.6.1 humanfriendly-10.0 importlib-metadata-6.11.0 kubernetes-29.0.0 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.17.1 opentelemetry-api-1.23.0 opentelemetry-exporter-otlp-proto-common-1.23.0 opentelemetry-exporter-otlp-proto-grpc-1.23.0 opentelemetry-instrumentation-0.44b0 opentelemetry-instrumentation-asgi-0.44b0 opentelemetry-instrumentation-fastapi-0.44b0 opentelemetry-proto-1.23.0 opentelemetry-sdk-1.23.0 opentelemetry-semantic-conventions-0.44b0 opentelemetry-util-http-0.44b0 orjson-3.9.15 overrides-7.7.0 posthog-3.5.0 pulsar-client-3.4.0 pypika-0.48.9 python-dotenv-1.0.1 starlette-0.36.3 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDJ3iVfV17xe",
        "outputId": "0736f99c-d64c-4033-b113-27b384b6fa89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#레퍼런스"
      ],
      "metadata": {
        "id": "MLzEzlHMbtoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#레퍼런스\n",
        "#https://rfriend.tistory.com/849"
      ],
      "metadata": {
        "id": "Gxftwoo40XxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 패키지 임포트"
      ],
      "metadata": {
        "id": "SzTzVPDRS11E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 패키지 임포트\n",
        "from langchain.document_loaders import PyPDFLoader  #pdf 파씽\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chat_models import ChatOpenAI  #langchain에서 openAI 활용을 위해\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings  #embbeding방식을 openAI로 설정하기 위해\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter   #텍스트 나누기\n",
        "from langchain.chains import RetrievalQA, ConversationalRetrievalChain  #QA와 대화형 QA 불러오기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "xaZ2qdCsxxX8",
        "outputId": "7b81264b-87f2-4103-a0d8-3c90d4da2cfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-467f35ff2568>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 패키지 임포트\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_loaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPyPDFLoader\u001b[0m  \u001b[0;31m#pdf 파씽\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorstores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChroma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m  \u001b[0;31m#langchain에서 openAI 활용을 위해\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m  \u001b[0;31m#embbeding방식을 openAI로 설정하기 위해\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 로컬에 api key 할당"
      ],
      "metadata": {
        "id": "e4NNmzo1TDPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "hlZztbjTx3st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#pdf 파싱 영역"
      ],
      "metadata": {
        "id": "uQKJp4_HTQim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pypdf를 통해 PDF를 불러오는 영역\n",
        "loader = PyPDFLoader('/content/drive/MyDrive/llm_test/2021_h03.pdf')  #경로 내 PDF 불러오기\n",
        "\n",
        "#loader를 documents에 할당\n",
        "documents = loader.load()\n",
        "\n",
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnWw49nRx7Ma",
        "outputId": "ca10eac8-6290-41ee-d4a3-87de1f451357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#텍스트 나누기"
      ],
      "metadata": {
        "id": "jorySfNQTURj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#텍스트 나누기로 청크 사이즈 1000씩 쪼개고 오버랩을 200으로 설정함\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "\n",
        "#스플릿된 텍스트를 texts에 할당\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfVl8qLy0_9f",
        "outputId": "bf5009b6-33a5-4c07-c9d4-d92b9084c58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2~3번 청크 내용 보기\n",
        "texts[60:61]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIOjfNyG1Dot",
        "outputId": "6db0f009-b84a-44ed-ce0d-2b3e443cdbd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='44\\n2. 시나리오별 투입산출 분석\\n▪ 경제적 파급효과를 산출하기 위해, 한국은행에서 2021년 6월 21일 발표한 2019년 생산자가격 기준 투\\n입산출표와 통합소분류 고용표를 사용하여 투입산출분석(input-output analysis) 실시 15)\\n\\U000f080f제2절 연구 방법론에서도 소개한 바 있지만, 분석의 기본 개념을 간략하게 다음과 같이 요약할 수 있음\\n\\U000f080f특정 산업(industry)에서의 최종 수요(final demand)의 증가는 생산량 증가로 이어지며,  그러한 생산량\\n의 증가로 인해 중간재로 사용되는 타 산업의 생산량 증가, 즉 간접적인 효과(indirect effect)가 나타 나게 \\n되고, 이는 다시 타 산업의 생산량의 증가로 이어지는 순환구조가 나타남\\n▪ 투입산출분석을 사용한 시나리오별 경제적 파급효과는 다음의 <표 4-9>로 정리할 수 있음\\n\\U000f080f각 시나리오별 지출총계는 <표 4-8> 맨 하단에서 제시하는 지출총계와 동일\\n<표 4-9> 시나리오별 경제적 파급효과\\n(단위: 억원, 명)\\n지출액 및 파급효과시나리오 1\\n유사사례 분석\\n(회귀분석)시나리오 2\\n관람의향 분석\\n(설문조사)시나리오 3\\n(평균 시나리오)\\n지출총계 1,272.59 1,157.08 1,225.15\\n생산유발효과 2,563.63 2,330.86 2,468.01\\n부가가치유발효과 1,063.22 966.74 1,023.63\\n취업유발효과 2,226.59 2,024.46 2,143.58\\n주석: 지출총계, 생산유발효과, 부가가치유발효과의 단위는 억원이며, 취업유발효과의 단위는 명임.\\n▪ 분석 결과, 이건희 컬렉션이 건립된다면 연 방문인원이 300만명 내외라는 전제하에, 우리나라에 약 \\n2,331-2,564억원 수준의 생산유발효과와 967-1,063억원 수준의 부가가치유발효과, 2,024-2,267 명 \\n수준의 취업유발효과가 발생할 것으로 예상함\\n\\U000f080f본 보고서에서는 이건희 컬렉션 미술관이 완전히 설립된 이후, 관람객의 지출에 의한 경제적 파급효과를', metadata={'source': '/content/drive/MyDrive/llm_test/2021_h03.pdf', 'page': 53})]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#벡터DB생성"
      ],
      "metadata": {
        "id": "aTaVcSpXTYu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터DB생성\n",
        "directory = 'index_store'  #디렉토리 명 지저정\n",
        "\n",
        "#textx에서 데이터를 받아와서 openAIembbeddings 방식으로 변환하고 directory에 반영한다.\n",
        "vector_index = Chroma.from_documents(\n",
        "    texts, # Documents\n",
        "    OpenAIEmbeddings(), # Text embedding model\n",
        "    persist_directory=directory # persists the vectors to the file system\n",
        "    )\n",
        "\n",
        "#vector_index에 영구 반영\n",
        "vector_index.persist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeE0HwGo1QRi",
        "outputId": "c6b50754-d0a2-4ddb-b764-f243f94da28a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#벡터DB에 PDF 추가"
      ],
      "metadata": {
        "id": "UFVz7ilSTies"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터store에 다른PDF 파일을 추가하기 위한 코드\n",
        "\n",
        "# pdf파일을 불러옴\n",
        "loader = PyPDFLoader('/content/drive/MyDrive/llm_test/2022_k05.pdf')\n",
        "\n",
        "# 위에 할당한 텍스트 스플린터로 텍스트를 나눔\n",
        "pages_new = loader.load_and_split(text_splitter)\n",
        "\n",
        "# 벡터store에 추가\n",
        "_ = vector_index.add_documents(pages_new)\n",
        "\n",
        "# 벡터index에 영구 반영\n",
        "vector_index.persist()"
      ],
      "metadata": {
        "id": "F3tgLU9F7lfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#리트리버 튜닝"
      ],
      "metadata": {
        "id": "i_FWA-LkTeIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 리트리버 생성하고 세부설정을 지정한다.\n",
        "retriever = vector_index.as_retriever(\n",
        "    search_type=\"similarity\", # Cosine Similarity\n",
        "    search_kwargs={\n",
        "        \"k\": 2, # Select top k search results\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "9njwbbfh2HVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LLM 할당, 파라미터 설정"
      ],
      "metadata": {
        "id": "yzO5Ef-oTnMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM할당하고 파라미터 설정하는 영역\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=ChatOpenAI(temperature=0.5, model=\"gpt-3.5-turbo\"),    #gpt-3.5-turbo, gpt-4\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True # source document which were used as source files\n",
        ")"
      ],
      "metadata": {
        "id": "Ak3GvccC2Nez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#결과 출력용 변수"
      ],
      "metadata": {
        "id": "8ydHKF28Trxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_llm_response(llm_response):\n",
        "    print(llm_response['result'])\n",
        "    print('\\n\\nSources:')\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        print(source.metadata['source'])"
      ],
      "metadata": {
        "id": "yE0mfJVj2g-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#사용자 질문 입력"
      ],
      "metadata": {
        "id": "14ZOyp10TuqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#사용자 질문입력\n",
        "user_content = input(\"user :\" )\n",
        "\n",
        "query = user_content\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "Ntdq7yad23mS",
        "outputId": "48519adb-badc-4bea-ac3d-09b9da29e13e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user :중국의 블록체인 정책 동향에 대해 알려줘\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'qa_chain' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dcd8e5a143c5>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mllm_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqa_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprocess_llm_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'qa_chain' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekql8TkkLeKc",
        "outputId": "eab06fdd-9817-4d17-b747-dc24a3df1999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': '문화관광콘텐츠 산업 분류체계 정립에 관해 설명해줘',\n",
              " 'result': '문화관광콘텐츠 산업 분류체계 정립은 다음과 같은 4단계 프로세스를 거칩니다:\\n1. **1단계**: 한국표준산업분류 대분류 기준을 활용하여 문화관광콘텐츠 산업과 관련된 대분류 3개를 추출합니다.\\n2. **2단계**: 세부 산업별 특수분류와 연계하여 문화예술, 관광, 콘텐츠 산업의 특수분류와 상위분류(중·소분류) 산업을 추출합니다.\\n3. **3단계**: 문화관광콘텐츠 산업에 큰 영향을 미치는 산업을 20% 이상의 비중을 가진 산업으로 추출합니다.\\n4. **4단계**: 문화관광콘텐츠 산업에 매우 큰 영향을 미치는 산업을 50% 이상의 비중을 가진 산업으로 추출합니다. \\n\\n이러한 과정을 통해 문화관광콘텐츠 산업을 정확하게 분류하고 해당 산업의 영향력을 분석할 수 있습니다.',\n",
              " 'source_documents': [Document(page_content='문화관광콘텐츠 산업 \\n노동시장 심층분석문화관광콘텐츠 산업의 노동시장 변화 분석\\n제6장', metadata={'page': 294, 'source': '/content/drive/MyDrive/llm_test/2022_k05.pdf'}),\n",
              "  Document(page_content='46 문화관광콘텐츠 산업의 노동시장 변화 분석 연구나. 분류체계 정립 과정\\n문화관광콘텐츠 산업 분류체계 정립을 위해 다음과 같이 3단계를 거치게 된다.\\n 1단계 : 한국표준산업분류 대분류 기준\\n- (방법) 문화관광콘텐츠 산업과 연관성이 높은 한국표준산업분류의 대분류 3개 추출\\n- (한계점) 문화관광콘텐츠 산업이 아닌 분야 일부 포함\\n 예시, 관광숙박이거나 관광음식점이 아닌 ‘I. 숙박 및 음식점업’도 포함됨\\n⇩\\n 2 단 계 :  세 부  산 업 별  특 수 분 류 와  연 계\\n- (방법) 문화예술, 관광, 콘텐츠 산업 특수분류와 연계된 세세분류의 상위분류(중·소분류) 산업 추출- (한계점) 산업분류 단위에 따라 문화관광콘텐츠 산업이 아닌 분야 일부 포함 예시, ‘49. 육상운송 및 파이프라인 운송업’에는 여객운송이 아닌 화물운송도 포함됨\\n⇩\\n 3단계 : 문화관광콘텐츠 산업에 미치는 영향 비중이 큰 산업 추출(20% 이상)\\n- (방법) 특수분류와 연계된 중·소분류 단위 사업체, 종사자 규모 비중 20% 이상 산업 추출 : 관광 산업의 비중을 명확히 알 수 없는 ‘음식점 및 주점업’ 분류 제외\\n : 사업체 및 종사자 규모 비중 산출(특수분류와 연계된 세세분류/특수분류와 연계된 중·소분류) 검토\\n : 사업체, 종사자 규모 비중이 모두 20% 이상인 경우만 추출- (한계점) 사업체, 종사자 수의 규모 비중에 초점을 두어 산업 영향과 상관없이 규모가 큰 사업 포함\\n⇩\\n 4단계 : 문화관광콘텐츠 산업에 미치는 영향 비중이 큰 산업 추출(50% 이상, 추가 논의)\\n- (방법) 특수분류와 연계된 중·소분류 단위 사업체, 종사자 규모 비중 50% 이상 산업 추출\\n : 3단계의 사업체, 종사자 비중 둘 중 하나라도 50% 이상인 경우만 추출\\n : 사업체, 종사자 비중이 모두 50% 이상이라도 소수의 대규모 종사자가 포함된 분류(영향력 미흡)는 제외\\n자료: 연구진 작성[그림 3-1] 문화관광콘텐츠 산업 분류체계 정립 과정\\n1) 1단계 : 한국표준산업분류 대분류 기준', metadata={'page': 103, 'source': '/content/drive/MyDrive/llm_test/2022_k05.pdf'})]}"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "e1QHXRYkR6QQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#chat history memory"
      ],
      "metadata": {
        "id": "mZwWCR1HUZ4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv_chain = ConversationalRetrievalChain.from_llm(\n",
        "    ChatOpenAI(temperature=0, model=\"gpt-4\"),\n",
        "    retriever=retriever,\n",
        ")"
      ],
      "metadata": {
        "id": "Xba_jJ_cZi_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = []"
      ],
      "metadata": {
        "id": "gv3hA0X2aOXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize our chat history.\n",
        "if \"chat_history\" not in locals():\n",
        "    chat_history = []\n",
        "\n",
        "user_content = input(\"user: \")\n",
        "query = user_content\n",
        "result = conv_chain.invoke({\"question\": query, \"chat_history\": chat_history})\n",
        "\n",
        "print(result[\"answer\"])\n",
        "\n",
        "# Add the current question and answer to the chat history.\n",
        "chat_history.append((query, result[\"answer\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "VsOOGtbhXj25",
        "outputId": "344bc116-8fdd-4e5e-a4b6-5ab21ba3db9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-d7898526aefa>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mchat_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0muser_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"user: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"chat_history\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mchat_history\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPsBeizQZ-zV",
        "outputId": "e97026be-2c87-4075-d972-1834c819c482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize our chat history.\n",
        "if \"chat_history\" not in locals():\n",
        "    chat_history = []\n",
        "\n",
        "user_content = input(\"user: \")\n",
        "query = user_content\n",
        "result = conv_chain.invoke({\"question\": query, \"chat_history\": chat_history})\n",
        "\n",
        "print(result[\"answer\"])\n",
        "\n",
        "# Add the current question and answer to the chat history.\n",
        "chat_history.append((query, result[\"answer\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmYNToIGYgFN",
        "outputId": "391b7c39-dbc2-42b1-efa9-fe13b4f07c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user: 김성진의 직급은?\n",
            "김성진의 직급은 한국문화관광연구원 선임연구위원입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBSxWh0bYMln",
        "outputId": "fca3d984-0b36-43e3-d74c-2134c03d73a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': '김성진의 직급은?', 'chat_history': [('너의 이름은 무엇입니까?', '죄송합니다, 제 이름을 알려드릴 수 있는 정보는 제공되지 않았습니다.'), ('너의 이름은?', \"I'm sorry, but I can't assist with that.\"), ('김형종이 참여한 연구는 무엇인가?', '김형종이 참여한 연구는 \"긴급재난지원금이 관광·문화예술·콘텐츠 소비지출에 미친 영향\"입니다.'), ('김성진은?', '김성진은 \"이건희 컬렉션 관람의 경제효과 분석\"이라는 연구에 참여하였으며, 그는 이 연구의 연구총괄을 맡았습니다.'), ('이중차분법을 활용한 연구를 전부 찾아줘', '죄송합니다만, 제가 인터넷 검색이나 데이터베이스 조회 기능을 가지고 있지 않아서 이중차분법을 활용한 모든 연구를 찾아드릴 수 없습니다.'), ('회귀분석을 활용한 연구는?', '회귀분석을 활용한 연구는 이건희 컬렉션 미술관의 방문객 수를 추정하는 것입니다. 이를 위해 세계 각국의 약 60여개 유명 미술관·박물관 데이터를 사용하여 회귀분석을 실시합니다. 만약 설명변수가 미술관이 소유한 명화의 개수라면, 명화를 10개 보유한 미술관의 방문객은 특정 수치의 방문객이 예상되며, 5개 소유한 미술관의 방문객은 다른 수치의 방문객으로 예상할 수 있습니다. 이 방법을 통해 다른 미술관·박물관의 정보로부터 가상의 이건희 컬렉션 미술관 방문객 추정이 가능합니다.'), ('김성진의 직급은?', '김성진의 직급은 한국문화관광연구원 선임연구위원입니다.'), ('김성진의 직급은?', '김성진의 직급은 한국문화관광연구원 선임연구위원입니다.')], 'answer': '김성진의 직급은 한국문화관광연구원 선임연구위원입니다.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5y93ipcgVb9f",
        "outputId": "0414d158-a6ee-4e44-b768-59596f38da72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('너의 이름은 무엇입니까?', '죄송합니다, 제 이름을 알려드릴 수 있는 정보는 제공되지 않았습니다.'), ('너의 이름은?', \"I'm sorry, but I can't assist with that.\"), ('김형종이 참여한 연구는 무엇인가?', '김형종이 참여한 연구는 \"긴급재난지원금이 관광·문화예술·콘텐츠 소비지출에 미친 영향\"입니다.'), ('김성진은?', '김성진은 \"이건희 컬렉션 관람의 경제효과 분석\"이라는 연구에 참여하였으며, 그는 이 연구의 연구총괄을 맡았습니다.'), ('이중차분법을 활용한 연구를 전부 찾아줘', '죄송합니다만, 제가 인터넷 검색이나 데이터베이스 조회 기능을 가지고 있지 않아서 이중차분법을 활용한 모든 연구를 찾아드릴 수 없습니다.'), ('회귀분석을 활용한 연구는?', '회귀분석을 활용한 연구는 이건희 컬렉션 미술관의 방문객 수를 추정하는 것입니다. 이를 위해 세계 각국의 약 60여개 유명 미술관·박물관 데이터를 사용하여 회귀분석을 실시합니다. 만약 설명변수가 미술관이 소유한 명화의 개수라면, 명화를 10개 보유한 미술관의 방문객은 특정 수치의 방문객이 예상되며, 5개 소유한 미술관의 방문객은 다른 수치의 방문객으로 예상할 수 있습니다. 이 방법을 통해 다른 미술관·박물관의 정보로부터 가상의 이건희 컬렉션 미술관 방문객 추정이 가능합니다.')]\n"
          ]
        }
      ]
    }
  ]
}